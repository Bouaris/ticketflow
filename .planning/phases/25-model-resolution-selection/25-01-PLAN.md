---
phase: 25-model-resolution-selection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/constants/storage.ts
  - src/lib/ai.ts
  - src/lib/ai-dependencies.ts
  - src/lib/ai-bulk.ts
  - src/lib/ai-chat.ts
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "When user overrides provider in ticket creation, the correct model for that provider is sent to the API"
    - "getEffectiveAIConfig reads persisted model choice from localStorage when available"
    - "All 11 affected functions across 4 files resolve model from the overridden provider, not the global provider"
  artifacts:
    - path: "src/constants/storage.ts"
      provides: "AI_MODEL_PREFIX storage key and getModelStorageKey helper"
      contains: "AI_MODEL_PREFIX"
    - path: "src/lib/ai.ts"
      provides: "getSelectedModel, setSelectedModel helpers and fixed getEffectiveAIConfig"
      exports: ["getSelectedModel", "setSelectedModel"]
    - path: "src/lib/ai-dependencies.ts"
      provides: "Fixed detectDependencies model resolution"
      contains: "resolveModelForProvider"
    - path: "src/lib/ai-bulk.ts"
      provides: "Fixed generateBulkItems and refineBulkItems model resolution"
      contains: "resolveModelForProvider"
    - path: "src/lib/ai-chat.ts"
      provides: "Fixed sendChatMessage model resolution"
      contains: "resolveModelForProvider"
  key_links:
    - from: "src/lib/ai.ts"
      to: "src/constants/storage.ts"
      via: "getModelStorageKey import"
      pattern: "getModelStorageKey"
    - from: "src/lib/ai.ts"
      to: "src/lib/ai-provider-registry.ts"
      via: "getProviderById for model resolution"
      pattern: "getProviderById\\(effectiveProvider\\)"
    - from: "src/lib/ai-bulk.ts"
      to: "src/lib/ai.ts"
      via: "resolveModelForProvider import"
      pattern: "resolveModelForProvider"
    - from: "src/lib/ai-chat.ts"
      to: "src/lib/ai.ts"
      via: "resolveModelForProvider import"
      pattern: "resolveModelForProvider"
---

<objective>
Fix provider override model resolution (GENX-03) and add model persistence infrastructure.

Purpose: When a user selects a different provider in ticket creation (e.g., switches from Gemini to Groq), the API call currently sends the wrong model ID (e.g., `gemini-2.0-flash` to the Groq API, causing a 404). This plan fixes all 11 affected call sites across 4 files (ai.ts, ai-dependencies.ts, ai-bulk.ts, ai-chat.ts) to resolve the model from the overridden provider's registry entry, and adds localStorage persistence for user model selection.

Output: Fixed model resolution in ai.ts, ai-dependencies.ts, ai-bulk.ts, and ai-chat.ts, new storage key + helpers for model persistence.
</objective>

<execution_context>
@C:/Users/Boris/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Boris/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-model-resolution-selection/25-RESEARCH.md

@src/constants/storage.ts
@src/lib/ai.ts
@src/lib/ai-dependencies.ts
@src/lib/ai-bulk.ts
@src/lib/ai-chat.ts
@src/lib/ai-provider-registry.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add model storage key and persistence helpers</name>
  <files>src/constants/storage.ts, src/lib/ai.ts</files>
  <action>
**In `src/constants/storage.ts`:**

1. Add `AI_MODEL_PREFIX: 'ai-model'` to the `STORAGE_KEYS` object (after `CUSTOM_PROVIDER_API_KEY_PREFIX`).

2. Add a new helper function after `getCustomProviderApiKeyKey`:

```typescript
/**
 * Build a storage key for a provider's selected model
 */
export function getModelStorageKey(providerId: string): string {
  return `${STORAGE_KEYS.AI_MODEL_PREFIX}-${providerId}`;
}
```

**In `src/lib/ai.ts`:**

3. Add import of `getModelStorageKey` from `../../constants/storage` (the file already imports `STORAGE_KEYS` from there, add `getModelStorageKey` to the same import).

4. Add two new exported functions right before `getEffectiveAIConfig` (around line 240):

```typescript
/**
 * Get user's selected model for a provider from localStorage.
 * Returns null if no selection persisted (use provider default).
 */
export function getSelectedModel(providerId: string): string | null {
  return localStorage.getItem(getModelStorageKey(providerId));
}

/**
 * Persist user's selected model for a provider.
 */
export function setSelectedModel(providerId: string, modelId: string): void {
  localStorage.setItem(getModelStorageKey(providerId), modelId);
}
```

5. Update `getEffectiveAIConfig` to read the persisted model choice. Replace the current implementation (lines 247-262) with:

```typescript
export function getEffectiveAIConfig(_projectPath?: string): {
  provider: AIProvider;
  modelId: string;
} {
  const globalProvider = getProvider();
  const providerConfig = getProviderById(globalProvider);

  // Read persisted model selection, falling back to provider default
  const selectedModel = getSelectedModel(globalProvider);
  const defaultModel = providerConfig?.defaultModel
    ?? (globalProvider === 'groq' ? AI_CONFIG.GROQ_MODEL
      : globalProvider === 'gemini' ? AI_CONFIG.GEMINI_MODEL
      : AI_CONFIG.OPENAI_MODEL);

  return {
    provider: globalProvider,
    modelId: selectedModel || defaultModel,
  };
}
```

6. Add a new helper function `resolveModelForProvider` right after `getEffectiveAIConfig`:

```typescript
/**
 * Resolve the correct model ID for a given provider.
 * Uses: persisted user selection > provider's defaultModel > hardcoded fallback.
 * This is the authoritative model resolution — use when provider may be overridden.
 */
export function resolveModelForProvider(providerId: string): string {
  const selected = getSelectedModel(providerId);
  if (selected) return selected;

  const providerConfig = getProviderById(providerId);
  if (providerConfig?.defaultModel) return providerConfig.defaultModel;

  // Ultimate fallback for unknown/deleted providers
  if (providerId === 'groq') return AI_CONFIG.GROQ_MODEL;
  if (providerId === 'gemini') return AI_CONFIG.GEMINI_MODEL;
  return AI_CONFIG.OPENAI_MODEL;
}
```

This provides the infrastructure needed by both this plan (Task 2) and Plan 02 (model dropdown UI).
  </action>
  <verify>Run `pnpm build` — must compile with no TypeScript errors. Verify `getSelectedModel`, `setSelectedModel`, `resolveModelForProvider` are exported from ai.ts. Verify `getModelStorageKey` is exported from storage.ts.</verify>
  <done>Storage key `AI_MODEL_PREFIX` exists in STORAGE_KEYS. Three new functions exported from ai.ts. getEffectiveAIConfig reads persisted model. Build passes.</done>
</task>

<task type="auto">
  <name>Task 2: Fix model resolution in all 11 affected call sites</name>
  <files>src/lib/ai.ts, src/lib/ai-dependencies.ts, src/lib/ai-bulk.ts, src/lib/ai-chat.ts</files>
  <action>
Fix all 11 call sites across 4 files that destructure `{ provider, modelId }` from `getEffectiveAIConfig` and then either override the provider but NOT the model, or use the global modelId without resolving per-provider. In each case, replace the pattern:

```typescript
// BEFORE (broken):
const { provider, modelId } = getEffectiveAIConfig(options?.projectPath);
const effectiveProvider = options?.provider || provider;
// ... later uses modelId (which is wrong when provider is overridden)
```

With:

```typescript
// AFTER (fixed):
const { provider } = getEffectiveAIConfig(options?.projectPath);
const effectiveProvider = options?.provider || provider;
const modelId = options?.modelId || resolveModelForProvider(effectiveProvider);
```

**Apply this fix in all 11 locations across 4 files:**

**In `src/lib/ai.ts` (7 call sites):**

1. **`generateItemFromDescription`** (~line 1183-1184): Replace the destructuring and add `resolveModelForProvider(effectiveProvider)`. The `modelId` variable is used later at ~line 1234 in the `generateCompletionWithRetry` call.

2. **`refineItem`** (~line 811-812): Same pattern. `modelId` is used in the `generateCompletionWithRetry` call further down.

3. **`suggestImprovements`** (~line 1347-1348): Same pattern. `modelId` is used at ~line 1363.

4. **`analyzeBacklogFormat`** (~line 1646-1647): Same pattern. `modelId` is used at ~line 1657 in `generateCompletion` call.

5. **`correctBacklogFormat`** (~line 1698-1699): Same pattern. `modelId` is used at ~line 1716 in `generateCompletion` call.

6. **`analyzeBacklog` (main body)** (~line 2015-2016): Same pattern. `modelId` is used at ~line 2058 in `generateCompletion` call.

7. **`analyzeBacklog` (catch/telemetry block)** (~line 2143-2144): Same pattern. This is in the catch block for telemetry recording — model resolution should still be correct for error tracking.

**In `src/lib/ai-dependencies.ts` (2 call sites):**

8. **`detectDependencies` (main body)** (~line 194-195): Same pattern. `modelId` is used at ~line 204.

9. **`detectDependencies` (catch/telemetry block)** (~line 244-245): Same pattern. Used for error telemetry.

**In `src/lib/ai-bulk.ts` (2 call sites):**

10. **`generateBulkItems`** (~line 450-451): Same broken pattern — destructures `{ provider, modelId }` then overrides provider with `options?.provider || provider` but keeps the wrong `modelId`. Apply the same fix:
```typescript
const { provider } = getEffectiveAIConfig(options?.projectPath);
const effectiveProvider = options?.provider || provider;
const modelId = options?.modelId || resolveModelForProvider(effectiveProvider);
```

11. **`refineBulkItems`** (~line 591-592): Same broken pattern. Apply identical fix.

**Important:** `resolveModelForProvider` is defined in `ai.ts`. In files that import from `./ai`, add `resolveModelForProvider` to the existing import statement:

- In `ai-dependencies.ts`: Add `resolveModelForProvider` to the existing import from `./ai` (~line 11).
- In `ai-bulk.ts`: Add `resolveModelForProvider` to the existing import from `./ai` (~line 11). The file already imports `getEffectiveAIConfig, buildTypeClassificationSection, buildTypeEnum, generateCompletionWithRetry` from `./ai`.

**In `src/lib/ai-chat.ts` (1 call site):**

12. **`sendChatMessage`** (~line 191): Destructures `{ provider, modelId }` from `getEffectiveAIConfig(projectPath)`. While this function does not have an `options?.provider` override, it still uses the raw `modelId` from `getEffectiveAIConfig` without going through `resolveModelForProvider`. Fix it for consistency and to ensure proper model resolution:
```typescript
const { provider } = getEffectiveAIConfig(projectPath);
const modelId = resolveModelForProvider(provider);
```
Add `resolveModelForProvider` to the existing import from `./ai` (~line 16).

**Do NOT modify:**
- `generateCompletion` itself — its internal model resolution is already correct (it's a good fallback)
- `CompletionOptions` type — `modelId` field already exists
- `src/lib/ai-questioning.ts` — already uses the correct `effectiveModel` pattern with `options?.modelId ?? modelId`
- `src/hooks/useAIFeedback.ts` — no provider override, uses global config directly for telemetry (will automatically benefit from Task 1's getEffectiveAIConfig update)
- Any function that does NOT override the provider (i.e., functions that just use `getEffectiveAIConfig` result directly without `options?.provider` override), EXCEPT ai-chat.ts which needs the fix for consistency
  </action>
  <verify>Run `pnpm build` — must compile with no TypeScript errors. Grep for the old broken pattern `const { provider, modelId } = getEffectiveAIConfig` — should return exactly 3 remaining matches: 2 in ai-questioning.ts (correct `effectiveModel` pattern) and 1 in hooks/useAIFeedback.ts (no provider override, uses global config). All 11 other occurrences must be eliminated. Grep for `resolveModelForProvider` — should return 12 total results: 1 definition in ai.ts + 7 usages in ai.ts + 2 usages in ai-dependencies.ts + 2 usages in ai-bulk.ts + 1 usage in ai-chat.ts.</verify>
  <done>All 11 affected call sites across 4 files resolve model from the effective provider. No function uses the global provider's model when a different provider is selected. Build passes. Old broken destructuring pattern eliminated.</done>
</task>

</tasks>

<verification>
1. `pnpm build` passes with zero errors
2. `grep -r "const { provider, modelId } = getEffectiveAIConfig" src/` returns exactly 3 matches — the 2 in `ai-questioning.ts` (already correct via `effectiveModel` pattern) and 1 in `hooks/useAIFeedback.ts` (no provider override, uses global config correctly). All other occurrences (11 call sites) must be eliminated.
3. `grep -r "resolveModelForProvider" src/` returns 12 total matches: ai.ts (1 definition + 7 usages), ai-dependencies.ts (2 usages), ai-bulk.ts (2 usages), ai-chat.ts (1 usage)
4. `getSelectedModel`, `setSelectedModel`, `resolveModelForProvider` are all exported from ai.ts
5. `getModelStorageKey` is exported from storage.ts
6. No unused imports or variables
</verification>

<success_criteria>
- GENX-03 gap is closed: provider override in ticket creation correctly resolves the model for the overridden provider
- Model persistence infrastructure exists (getSelectedModel/setSelectedModel) for Plan 02 to consume
- getEffectiveAIConfig returns persisted model when available
- All 11 previously broken call sites across 4 files use resolveModelForProvider
- Build passes cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/25-model-resolution-selection/25-01-SUMMARY.md`
</output>
